%----------------------------------------------------------------------------------------
%	DATA ACQUISITION AND PREPARATIONS
%----------------------------------------------------------------------------------------

\section{Organization and data acquisition}
\label{ch:DataAcquisition}

In the second chapter of the report, the first stage of the study project is discussed, namely organizing, researching, and collecting the data.

The first section of the chapter~\ref{sec:Roadmap}~\nameref{sec:Roadmap} gives an overview of the time management of the study group. It is followed by the subchapter~\ref{sec:Organization}~\nameref{sec:Organization} in which communication and teamwork are assessed. In~\ref{sec:DataCollection} \nameref{sec:DataCollection}, the acquisition of the data from the sorting machine Autoselect ATS~II is described in more detail. The last section~\ref{sec:Literature}~\nameref{sec:Literature} presents the retrieved literature concerning the issue of agricultural product classification with machine learning based approaches.

\subsection{Roadmap of the project}
\label{sec:Roadmap}

At the beginning of the project, a roadmap was created to structure the year into different working stages as well as to have an overview of the tasks and problems that needed to be addressed.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.43]{Figures/chapter02/new_timetable.png}
	\decoRule
	\caption[Timetable of the Project]{\textbf{Timetable of the Project}~~~The upper timeline shows the estimated time of the study project from April 2019 to April/Mai 2020. The lower timeline displays how the time was spent. Both timelines differ in that the year was more optimistically planned than realized. A major factor was the lack of experience of the participants concerning the conduction of a larger project with many co-workers as well as concerning the general implementation of the preprocessing stage for machine learning classification. Another factor influencing the shifted timeline was the appearance of a fifth major stage, the \emph{Manual Labeling}.}
	\label{fig:Timetable}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{Figures/chapter02/roadmap_planned.png}
	\decoRule
	\caption[Planned Roadmap]{\textbf{Planned Roadmap}~~~The figure shows the planned roadmap of the study project. It reveals how the time needed for each task was estimated in the beginning of the project.}
	\label{fig:RoadmapPlanned}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{Figures/chapter02/roadmap_actual.png}
	\decoRule
	\caption[Actual Roadmap]{\textbf{Actual Roadmap}~~~A roadmap that shows how the time was spent.}
	\label{fig:RoadmapActual}
\end{figure}

The timetable in~\autoref{fig:Timetable} gives a broad outline of the major stages of the project. In the upper timeline of the figure, it was estimated how much time for a specific phase is needed, whereas in the lower timeline the real time spent for the stage is given. Both timelines are structured to display the project year, starting in April 2019 and ending in April/Mai 2020. The months are represented by the x-axis while the colors mark the different working stages.

The project comprises four to five major stages: \textit{Data Collection \& Organization}, \textit{Preprocessing}, \textit{Manual Labeling}, \textit{Classification}, and \textit{Evaluation}. A detailed representation of the single tasks attributed to each stage can be found in the roadmaps in~\autoref{fig:RoadmapPlanned} and~\autoref{fig:RoadmapActual}. The project started with the data collection and the organization of the study project. During the first stage, the images were recorded with the sorting machine, while the major planning and research for the project took place. In the second phase, most of the preprocessing happened, that is, preparing and labeling the image data. The classification stage includes the time spent on the machine learning approaches which were implemented and trained on the asparagus data. In the last stage, the approaches were evaluated and their results were compared. The different stages overlapped to a certain degree. For the purpose of this figure, the start and end time is displayed as a hard boundary.

When comparing both timelines, some distinctions can be recognized. The upper timeline shows that preprocessing was estimated to be done by September. However, the phase continued until October, as can be observed in the lower timeline. Furthermore, the time for labeling a sufficient amount of images was underestimated, resulting in adjustments of the time attributed to this task. More specifically, it led to the \textit{Manual Labeling} of the image data receiving its own phase in the timetable, independent of the preprocessing phase.

The differences are depicted with different color codings. While the main focus of this project was supposed to be the application of different machine learning techniques to classify the data (color-coded in blue and green), the preprocessing phase and the data set creation/manual labeling posed to be most time-consuming (color-coded in orange and yellow).

In~\autoref{fig:RoadmapPlanned} and~\autoref{fig:RoadmapActual}, the stage specific tasks can be seen in more detail. Again, both figures display the estimated time and the actual time, respectively. The headlines serve as a division into the major stages except for the first heading, \emph{Constant Work}, which shows the tasks that demanded continuous attention and effort throughout the year. The duration of tasks is represented in blue, while the yellow lines mark milestones that are explained in the legends.

\subsection{Organisation of the study group}
\label{sec:Organization}

In this chapter, the management of the work distribution and the communication are taken into focus. For this the tools that were used for communication and organization will be examined as well as the structure of the group work.


\subsubsection{Communication}
\label{subsec:Communication}

The main communication consisted of weekly meetings in which the working process was discussed and new tasks were distributed. In addition to those meetings, different platforms were used, which worked with varying degrees of success. Used platforms were Asana, GitHub and Telegram to facilitate the communication aside from group meetings. The different means of communication will be described and evaluated in the following section.

\bigskip
Regular meetings made up the core organization of our project. During the meetings a discussion leader and a protocol writer were picked.\footnote{The protocols were saved for review in the GitHub project at \\ \url{https://github.com/CogSciUOS/asparagus}} The meetings were characterized by long discussions about how to approach the upcoming project step and how to tackle the next challenge. The project’s supervisors were usually present at the meetings, to bring in their expertise and to give the opportunity to ask concrete questions. During the first half of the project, tasks were distributed at the end of each meeting. In the subsequent meeting the working progress was discussed. This procedure was changed in the second half of the project. A schedule was used that described the different tasks and deadlines in detail. Additionally, we regularly gathered for co-working. The organizational meetings were continued, during which everyone gave precise and structured reports on their area of responsibility. This helped us to spend less time discussing and have more time for task-relevant work.

The majority of important information was exchanged via Telegram~\footnote{Telegram is a cloud-based instant messaging service for the use on smartphones, tablets and computers.}.  Starting from the first meeting, we had a constant conversation in a group chat on Telegram, in which we informed each other about the status of the project as well as support each other by answering questions. The group chat also created space for mutual motivation when needed.

Additionally, Asana was used in the beginning of the project. The communication platform is usually used to distribute tasks and to communicate about them. Many integrations of other applications, such as Slack, can help to achieve this. However, the tasks were easier to distribute in direct consultation at physical meetings and results could be easier demonstrated or discussed. If we had relied on communication with Slack or other agreed services or applications, it might have made more sense, but Asana alone has proven to be inefficient in our use case.

During the project, it was further learned how to work with GitHub~\footnote{GitHub is a web-based popular platform using the version control system Git that helps developers to store and manage their code, and track and control changes to their project.}. Git allowed us to work from anywhere, which facilitated the workflow.

Furthermore, we were able to automatically create documentations via Sphinx. This means that by adhering to the style conventions, the protocols, work schedules, manuals, and code comments were automatically included in our documentation.\footnote{see our documentation at~\url{https://asparagus.readthedocs.io/en/latest/}}


\subsubsection{Teamwork}
\label{subsec:Teamwork}

This section starts by introducing the team members and their previous experiences. It is followed by a description of the practical aspects of teamwork, the working structure, and the distribution of project-relevant tasks.

\bigskip
The project was an initiative of one of the students. A large part of the project members knew each other in private but had not yet worked together. Further students joined the project after its public announcement to complete the team. Thus, the group consisted of members with varying degrees of knowledge about each other. The team was initially made up by Josefine Zerbe, Katharina Groß, Malin Spaniol, Maren Born, Michael Gerstenberger, Richard Ruppel, Sophia Schulze-Weddige, Luana Vaduva, Thomas Klein, and Subir Das. None of the members had yet worked together as such on a project of this scope. During the course of the project, three members left the team for various reasons. Thomas left in July due to a change in his study program. Further, Luana and Subir left in October to pursue different study projects.

The members brought a wide variety of backgrounds into the team through different bachelor programs or different majors in the broader field of Cognitive Science. In the beginning of the project, the team members had little to no experience in the application of computer vision or neural networks. The motivation of most students was to pursue new and interesting tasks in these fields. Four students had a theoretical background in computer vision, six students had gained some experience with neural networks through the course ``\acrshortpl{ann} with TensorFlow’’, taught at the University of Osnabr{\"u}ck. Some had also taken machine learning classes during their study program. Git was previously only used by three students, but none of them were experts on its usage. Further, the team had neither experience with the Grid system of the \acrshort{ikw}, nor with running jobs on different machines. None of the members had prior knowledge about project management or task organization on a broader level.

\bigskip
In the beginning, the team lacked some structure and a clear distribution of individual roles. One reason for this could have been the harmonious atmosphere between team members. Further tasks such as the trips to the asparagus farm strengthened the team spirit and the social interactions. Thus, the task distribution was  very dynamically structured by making every decision democratically. Most tasks were performed in smaller teams of two to three people.  During meetings, possible next tasks were formulated but  without assigning them to specific members or working groups. This resulted in a lot of unassigned tasks and a discontinuous workflow. 

In August, the organization was restructured. On the one hand, a new structure for task distribution seemed more appropriate, instead of a democratic distribution. On the other hand, the strengths of the individual team members should be used more efficiently. Some team members had less programming experience than others. They had difficulties realizing certain tasks in an equal time period and with the same precision as others. Although they had good ideas in terms of concept, these were not implemented quickly enough to include them into the project. Nevertheless, it gave the opportunity to acquire new programming skills. To integrate more of the strengths that the single team members brought and to tackle the issue of time management, it was decided to write a work schedule that distributed the work more appropriately, gave an overview of the tasks that still had to be done and showed how much time was left to do them.

The supervision of the work was divided into manager roles, which means that the work was split into different main fields. Each member was responsible for managing their assigned area, distributing tasks and keeping an overview of the relevant work inside their working field. The manager could be consulted for questions, when in need of discussion, or for feedback. The meetings became more effective due to the new structure, and there was less discussion concerning task distribution. 

Further, common working hours on campus were introduced. The common working hours ensured that questions and decisions that arose could be discussed in person. This was especially helpful when different tasks overlapped and required communication and agreement.

\bigskip
In conclusion, the team structure and the distribution of work changed over the course of the project. The strengths of single members were used more efficiently and the supervision of working areas led to a more structured time management and task distribution. 


\subsection{Data collection}
\label{sec:DataCollection}

In this section the asparagus sorting machine at Gut Holsterfeld is described. Then the process of collecting labeled and unlabeled data is reported.

The machine Autoselect ATS~II (2003) is designed for sorting white and green asparagus (see~\autoref{fig:SortingMachine}) \citep{autoselectanleitung}. The asparagus is arranged on a conveyor belt that runs it through the recording section of the machine. Here, a camera takes three pictures per asparagus spear (see \autoref{fig:SortingMachineSketch} and \autoref{fig:ExampleImagesAnna}). Small wheels on the conveyor belt rotate the asparagus in the meantime so that it can be photographed from several positions. In the best case, on each image a different side of the asparagus is recorded. The conveyor belt transports the spear further and it is sorted into a tray depending on the chosen class label by the machine. The sorting is based on the parameters for width, length, shape, curvature, rust, and color. A total of 30 criteria for classifying an asparagus spear are used to describe these parameters. The calculation of the single features is based on a classical analytical approach. For example, the parameter for color detection is composed of eight sub-parameters. Each spear is reviewed at different areas (the head of the asparagus, the area below the head, and the stem) and judged for its hue in percentage. The values are compared and, according to a threshold, the spear is sorted into a color category (e.g.\, white or violet). For all parameters, there is a minimal threshold and a maximal threshold. As another example, the parameter for width detection calculates at three points at the asparagus (top, middle, and bottom part). From these three values, an average value is calculated that decides in which category the asparagus is sorted. If an asparagus exceeds the maximal threshold for parameter detection, it is not recognized and cannot be sorted accordingly. The same holds for values below the minimal threshold. Thus, all parameters have to have an upper and a lower threshold, including parameters that decide the presence of features like shape, curvature, and color. When evaluating what parameter boundaries to choose, it is recommended to check that most asparagus spears tend to be in between the average value and the maximal threshold, with a larger tendency to accumulate around the average value. Reportedly, the parameters and their respective ranges can be freely chosen by the user and can in this way be fitted to the needs of the respective asparagus farm~\citep{autoselectanleitung}.

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.9\textwidth]{Figures/chapter02/asparagusconveyerbelt_new.png}
	\decoRule
	\caption[Sketch of the Image Capturing Process with the Autoselect ATS II]{\textbf{Sketch of the Image Capturing Process with the Autoselect ATS II}~~~The asparagus spears are transported on a conveyor belt. After being washed and cut, the spears pass the camera field. Images are taken of three compartments, so that each asparagus spear is photographed three times in each position (a, b, c). The camera system is connected to a computer on which the sorting software runs. Depending on the resulting classification, the spear is sorted into the corresponding output tray.}
	\label{fig:SortingMachineSketch}
	\vspace{15pt}
	\centering
	\includegraphics[scale=0.6]{Figures/chapter02/sortingmachine_front.png}
	\decoRule
	\caption[The Autoselect ATS II at Gut Holsterfeld]{\textbf{Autoselect ATS~II at Gut Holsterfeld}~~~In the figure the asparagus sorting machine Autoselect ATS~II at Gut Holsterfeld can be seen. The conveyor belt transports the asparagus from the left side of the image to the right side. It thereby passes the camera system. The display of the machine gives information on the parameters and the images. The machine is mainly controlled from here.}
	\label{fig:SortingMachine}
\end{figure}

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.3]{Figures/chapter02/sorting_machine_slots.png}
	\decoRule
	\caption[Output Trays of the Sorting Machine]{\textbf{Output Trays of the Sorting Machine}~~~Depending on the class label, the asparagus is sorted into one of the machine's 16 trays.}
	\label{fig:SortingMachineSlots}
\end{figure}

Before the first use of the machine, all parameters are selected after a calibrating charge of asparagus has run through the machine. Then, the user can adjust the thresholds accordingly.

According to the manual, the number of quality classes is selectable. The user can define the order of quality classes by choosing the arrangement of parameters. The manufacturer suggests to first sort for length and width, then use the parameters that sort for color, and the parameters for shape detection last.

The accuracy of the sorting machine is described to be as good as 90\% best case by the manufacturer, while the farmer at Gut Holsterfeld reported it to be around 70\% at best, with re-sorting being necessary by professional sorters. Especially categories like Blume or Hohle were considered to be inconsistent by both, manufacturer and farmer. Further information could not be given on the software of the machine. A meeting with a representative of the engineering company HMF~\footnote{see \url{www.hmf-hermeler.de}}  that manufactured the sorting machine was arranged. Unfortunately, the source code itself was not available to HMF as it was produced by another company. 

\bigskip
In the following it is described how the image data was collected. It is possible to save images with the Autoselect ATS II, however, the storage space on the machine is very limited. Further, the selection of images to be saved is restricted to only 1000 images.
One workaround to the problem is the installation of the Teamviewer software~\footnote{see \url{https://www.teamviewer.com/en/}} on the machine and the connection of an external hard drive. After the installation, the process of image collection could be started remotely. This work was very ineffective and time-consuming. The data could not be directly transmitted to another computer because the internet speed at the farm is too slow. An automatic transfer of the images to the external hard drive was not possible until the installation of an automatic file moving service, for which the requirements are described below.

The file moving program needs to transfer the images to a new saving destination and has to run in the background without disturbing the workflow of the sorting machine. After research on background processes and programs, the decision was made to use a service, that is, a system process running independently of any program. The service manages moving the newly generated image files, as described in detail in the appendix in \autoref{subsec:FileService}.

The project members split in groups of two and exchanged the hard drive two times a week. The collected images were then transferred to storage capacities of the university.

The label that the machine attributes to each asparagus is not reliable. Therefore, sending the asparagus through the machine a second time would be the only way to gather labeled images. Unfortunately, a second sorting is not good for the quality of the asparagus. Further, at least one project member has to be involved in the re-sorting and, thus, has to be present at the farm. The sessions of exchanging the external hard drive and collecting labeled image data were combined.

\begin{figure}[!h]
	\centering
	\vspace{20pt}
	\begin{subfigure}{0.3\textwidth}
		\includegraphics[width=0.95\linewidth]{Figures/chapter02/anna_a.png}
		\caption{left}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\includegraphics[width=0.95\linewidth]{Figures/chapter02/anna_b.png}
		\caption{middle}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\includegraphics[width=0.95\linewidth]{Figures/chapter02/anna_c.png}
		\caption{right}
	\end{subfigure}
    \caption[Example Asparagus Images]{\textbf{Example Asparagus Images}~~~Example pictures of the quality class I~A~Anna. The asparagus is arranged on a conveyor belt that runs it through the recording section of the machine, where a camera takes three pictures. In picture (A) the target asparagus is to the left, in (B) it is in the middle, and in (C) it is to the right. Small wheels on the conveyor belt rotate the asparagus in the meantime so that it can be photographed from several positions. In the best case, on each image a different side of the asparagus is recorded. The conveyor belt transports the asparagus further and it is sorted into a tray depending on the chosen quality class by the machine. 
}
    \label{fig:ExampleImagesAnna}
\end{figure}

\bigskip
An example image of the received data can be seen in~\autoref{fig:ExampleImagesAnna}. There are three pictures per asparagus. The image resolution is $1040\times1376$ pixel per image, with an RGB color space.

\begin{table}[!htb]
	\centering
	\resizebox{.95\linewidth}{!}{%
	\begin{tabular}{|lr|lr|lr|}
		\hline
		\textbf{Class Label~~~~~} & \textbf{Nr. of Images} & \textbf{Class Label~~~~~} & \textbf{Nr. of Images} & \textbf{Class Label~~~~~} & \textbf{Nr. of Images} \\
		\hline
		I~A Anna		& 1005	& II~A	& 1051 	& Blume	& 1717	\\
		I~A Bona		& 908 	& II~B 	& 1468 	& Suppe	& 1157	\\
		I~A Clara	& 513 	& Rost 	& 1169	& Bruch	& 309	\\
		I~A Krumme	& 936 	& Dicke & 749 	& {}		& {}		\\
		I~A Violett	& 1514 	& Hohle	& 775 	& {}		& {}		\\
		\hline
	\end{tabular}%
	}
	\caption[Collected Images with Class Label]{\textbf{Collected Images with Class Label} \\ In this table, the number of collected images with a class label is reported. This was achieved by running pre-sorted spears a second time through the sorting machine}
	\label{tab:LabeledClassNumber}
\end{table}

In total, 612113 images were collected, with each class label being represented with at least 309 images, corresponding to 103 asparagus.

At the asparagus farm Gut Holsterfeld, 591495 labeled and unlabeled images were collected with the Autoselect ATS~II. The number of unlabeled data is 578226 images, thus, around 192742 different asparagus spears. Of the labeled data, the number of images that were collected per quality class can be found in \autoref{tab:LabeledClassNumber}. The image number does not represent the number of different asparagus spears, as each asparagus spear is represented by three distinct images.

\begin{figure}[!ht]
	\centering
	\vspace{20pt}
	\begin{subfigure}{0.3\textwidth}
		\includegraphics[width=0.9\linewidth]{Figures/chapter02/querdel_a.png}
		\caption{left}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\includegraphics[width=0.9\linewidth]{Figures/chapter02/querdel_b.png}
		\caption{middle}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\includegraphics[width=0.9\linewidth]{Figures/chapter02/querdel_c.png}
		\caption{right}
	\end{subfigure}
	
	\begin{subfigure}{0.3\textwidth}
		\vspace{10pt}
		\includegraphics[width=0.9\linewidth]{Figures/chapter02/querdel_d.png}
		\caption{upper part}
	\end{subfigure}
    \caption[Example Asparagus Images Querdel's Hof]{\textbf{Example Images Querdel's Hof}~~~Example pictures of the asparagus of the farm Querdel's Hof. In picture (A), the asparagus spear is to the left, in (B), it is in the middle, and in (C) it is to the right. A fourth picture (D) is taken with a second camera with focus on the upper part of the asparagus.}
    \label{fig:ExampleImagesQuerdel}
\end{figure}

Additionally, a few images could be recorded at another asparagus farm, Querdel’s Hof~\footnote{see~\url{https://www.querdel.de/}}, in Emsb{\"u}ren. The farm sorts the asparagus with an updated version of the Autoselect ATS~II at Gut Holsterfeld, that is, it uses the same software but other hardware. In particular the resolution of the camera was improved and a second camera was installed that focuses on the head region of the asparagus. At Querdel’s Hof, 20616 images were collected in total, 76 from the class label ``normal’’, 152 from the class label ``violet/flower’’, and 20388 unlabeled images. Each asparagus spear is represented by four images: three images show the asparagus from different perspectives and a fourth image depicts solely the head region. Example images for one asparagus can be seen in~\autoref{fig:ExampleImagesQuerdel}. No internet connection could be established to the farm, thus, no further images were collected. Moreover, the data format of the images from Querdel’s Hof is different to the data from the farm Gut Holsterfeld, due to the additional head image. Therefore a combination of both data sets was not convenient. 


\subsection{Literature on food classification using computer vision}
\label{sec:Literature}

In the classification of food products, there are numerous possibilities to apply classical machine learning and \acrshort{ann} approaches for classification tasks on image data~\citep{bhargava2018fruits,brosnan2002inspection}.


For the scope of this investigation, we decided to focus our literature search on fruit and vegetable quality evaluation using computer vision and machine learning. Compared to other fields, research and evaluation in agricultural classification shares many characteristics and faces similar difficulties.

The quality inspection based on computer vision is usually constituted into five main steps: image acquisition, preprocessing, image segmentation, feature extraction and classification~\citep{bhargava2018fruits}. Moreover, most data in agriculture is based on photographic images. Also the features of interest are similar for different kinds of fruit or vegetable. Frequently by traditional computer vision techniques inspected features concern color, shape, size, texture, and defect~\citep{bhargava2018fruits}. This makes other papers in the field of agricultural evaluation directly comparable to our case. Moreover, we hope to get an impression of the state of the art of how many images are needed in our case, how high the image resolution needs to be, what kind of computer vision approaches could be helpful as a starting point,  and also to become aware of known challenges.

\bigskip
None of the found papers were suitable as blueprints for the asparagus classification project. However, some of them helped to get an idea of how to proceed with the project. For example, some papers show how the preprocessing phase could be structured~\citep{mery2013automated}, or they evaluate the machine learning methods that were already used on other food classification tasks~\citep{bhargava2018fruits}. Further, some of the literature is concerned with the classification of food products but not with differentiating between as many classes as 13~\citep{diaz2004comparison,kilicc2007classification}. Often, the variance in the food products, that is, the quality as well as the type of food used is either too high~\citep{zhang2012classification} or too low~\citep{kilicc2007classification,al2011dates} in comparison to the variance in our project data.  One paper evaluates the sorting of asparagus, however, it only does so on a small data set with three categories of green asparagus~\citep{donis2016classification}. Further papers on food classification are not detailed enough in their explanations and do not share the information needed for replication~\citep{pedreschi2016grading}. Another paper is mainly about the implementation of a certain toolbox~\citep{mery2013automated}.

Even though no specific paper was used as guidance to our project, some specific papers inspires us to try out certain algorithms, such as PCA ~\citep{Vijayarekha2008, Zhu2007}) or neural networks ~\citep{Jhuria2013, Pujari2014}. Moreover, the literature review made us aware of the limiting fact that images of fruits and vegetables are captured mainly from one direction~\citep{bhargava2018fruits}.The literature suggests that performance might improve, if more perspectives are taken into account. Moreover, the literature shows that different authors use different color spaces such as CIE Lab, RGB or HSI ~\citep{Liming2010, Garrido-Novell2012, Kondo2010}. This further inspired us to apply color quantization on our data.

\bigbreak
As the available data was only sparsely labeled, further research was done to evaluate the use of a semi-supervised learning approach~\citep{olivier2006semi,zhu05survey}. Details about the corresponding literature can be found in~\autoref{sec:SemiSupervisedLearning}. In regards to deep learning-based approaches, classical neural networks -- such as AlexNet \citep{alexnet2012original}, \acrshort{vgg}16/\acrshort{vgg}19 \citep{vgg2014original}, GoogleNet \citep{googlenet2015original}, Capsule Networks \citep{capsulenet2017original},  DenseNet \citep{densenet2017original}, ResNet \citep{resnet2016original} or \acrfull{nin} \citep{lin2013network} -- were assessed for better understanding of the range of possible pre-trained networks and ideas for network structures. Also, classical computer vision approaches were considered, like multiclass \acrfullpl{svm} \citep{prakash2012multi}.
