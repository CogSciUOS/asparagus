%----------------------------------------------------------------------------------------
%	DISCUSSION
%----------------------------------------------------------------------------------------
\section{Discussion}
\label{ch:Discussion}

In our study project we pursued three main objectives. The main goal was to develop and improve algorithms for asparagus classification. The second objective is closely linked to this and relates to best practices in relation to applied data science and big data. This included storage of data on remote servers and computationally expensive procedures that are required for training in the computational grid of Osnabr{\"u}ck University: The methodological aspect of our study project. As our work also served as a sample project to learn more about possibilities to effectively organize collaborative work we also targeted at the organizational aspect that is closely linked to project management. In the following, the core results with respect to named objectives are shortly named and discussed.


\subsection{Classification results}
\label{sec:DiscussionResults}

Asparagus spears have several features that we aimed to extract. Some features such as the length and width of asparagus spears were undoubtedly measurable using a pure computer vision approach that does not rely on machine learning. For others, direct filtering was not easily possible because no clear cut definition of features, such as curvature or violet, exists, that is precise enough to be implemented directly. Although relevant information can easily be extracted, the rules to infer the desired binary features are inaccessible: On one side, decision boundaries for binary classifiers have to be found. On the other side, the perception of the features color or curvature has been shown to be very subjective. Moreover, filtering features such as flower has been proven difficult. Named attribute relates to details in a few pixels, comes in different forms, and highly depends on the perspective. Because of these reasons machine learning must be employed to successfully classify asparagus.

We designed several neural networks and applied them in different ways to analyze and classify a large-scale asparagus image data set. Some approaches worked better than others, as can be concluded from \autoref{ch:Summary}.

\bigskip
Training \acrshort{mlp} classifiers on histograms of palette images has proven a promising approach to predict color features. Named histograms contain information about the fraction of foreground pixels that correspond to violet or rusty colors. As \acrshortpl{mlp} have few parameters, the design is rather trivial and the training process quick. The results are considered as a good baseline performance for rusty body and violet. The application on palette images that show asparagus heads only might also be suitable to predict the feature rusty head. This is yet to be tested. \acrshortpl{mlp} have also shown to be suitable when applied to predict the binary curvature feature based on partial angles. The fact that predictions are far from perfect might be due to inconsistencies in the training data. One may assume, however, that the models generalized well and represent rules that relate to average opinions or definitions of highly subjective features such as color or curvature.

\bigskip
Feedforward  \acrshortpl{cnn} were applied to predict individual features, for multilabel prediction and predictions based on snippets that depict asparagus heads. In addition, effects of a custom loss function were tested. Promising in the multilabel prediction is that not only individual features, but also the relation between features can be considered in the learning process. Our multilabel  \acrshort{cnn} reaches an accuracy up to 87\%, which seems high. However, when looking at the accuracy and loss values over time, one can see that the model does not improve much. While sensitivity and specificity improve, and therefore indicate learning, the validation loss remains high, indicating overfitting. This model seems to be especially sensitive to the imbalance between 0 and 1 in the label vectors. Concerning this, there is still room to play around with our parameters to further improve the architecture.

\bigskip
Applying \acrshort{pca} on individual features and projecting the image information into a smaller dimensional subspace showed promising results. It revealed that the first principal components managed to capture most of the information. However, differences between most features seem to be too small to be adequately represented in the low dimensional space. In this approach, the features width, length and hollow seem to be classifiable with high performance, and the features bent and rusty body seem to be most difficult. Width, length and hollow (as hollow asparagus is likely to be thick) are features that can be related to the shape and spatial appearance of the spear in the picture. This walks together with the findings that the first principle components (so the most important ones) only refer to the appearance of the asparagus in the picture and shows the same picture for all asparagus. This leads to the assumption that the spatial appearance is counted as the most important feature, rather than taking the surface of the spears into account. This problem could be improved by generating pictures, where the possible asparagus positions are equally distributed over the pictures. Another reason for the similarities between the first principal component pictures is that one asparagus can have many features. Therefore the same pictures can be used for several feature pcas. As asparagus with only one present feature is rather difficult to find, another solution to attract this problem needs to be found.

\bigskip
Similarly, \acrlong{vae}s were used to derive a low dimensional representation using unsupervised learning. While some features such as the width and length are mapped to clearly differentiable regions in latent asparagus space, this is not the case for many others. Only as a tendency, spears labeled as bent are for example mapped to regions in the lower periphery. Autoencoders are known for blurry reconstructions. This is a possible explanation for the lack of clusters in latent space for features that relate to details that are not sufficiently reconstructed.

\bigskip
Convolutional autoencoders were used for semi-supervised learning. However the results for this approach can be described as merely mediocre. One problem is arguably the mentioned insufficiency in reconstructing details. As details such as brown spots define target classes (e.g. rusty head) and they are not present in latent space. It is hard to establish a correlation of the respective latent layer activation and the target labels. Larger input image sizes or different network architectures that are suitable to reconstruct higher detail images could potentially help to improve performance of semi-supervised learning.

\bigskip
Detecting the feature rusty head has proven rather difficult even though a dedicated network was trained on snippets that show asparagus heads in rather high resolution. This is potentially the case because details that are hardly visible even to the human eye have to be considered that occur in different locations. Although better results are achieved for the feature flower, the same most likely holds for this category as well. In contrast, better results are achieved for features that relate to the overall shape of asparagus spears instead of fine details. This holds for the category hollow as well as  for curvature. Color features are detected especially well based on histograms of palette images while \acrshortpl{cnn} have proven suitable to detect shape related features.

In summary, we successfully measured the width and height of asparagus spears and were able to develop detectors for the other features that performed surprisingly good, given the moderate inter-coder reliability that was partially due to unclear definitions of binary features such as bent or violet.


\subsection{Methodology}
\label{sec:DiscussionMethodology}

Looking back, there are several methodological issues, which we would process differently now. We started our study project at the beginning of April. This is as well the beginning of the asparagus harvesting season. Therefore,  we were able to start collecting data straight away. On the down-side, we had to start collecting data without a detailed plan in advance. Planning the data collection ahead could have made the data acquisition more efficient, and structured. Afterwards we could not change relevant parameters to answer a lot of organizational and methodological questions such as: How much data do we need? What format do we need it in? Is autonomous calibration possible? How exactly do we store the images effectively and efficiently? Is the setup as we need it? And if not, how can we improve it? What kind of measurements or changes do we want to perform with the camera? Is the illumination as we want it? Could stereo cameras or other 3D view techniques such as depth cameras or laser grid be used? Would we integrate an additional camera taking pictures from the bottom of the spear or from the head region separately?  What should our pipeline look like? How can we get labeled data right away?

\bigskip
As already mentioned, there was a misunderstanding between the group and the supporting asparagus farm about the data type necessary. The already existing images were too few, and unlabeled. Therefore, we spent the entire asparagus season with data acquisition instead of starting with preprocessing as planned originally. The number of labeled images that were collected by running re-sorted classes though the machine is arguably insufficient to learn classes using the chosen deep learning approaches~\citep{russakovsky2013detecting,russakovsky2010attribute,how_many_images}. Therefore, a lot of time was spent on preprocessing and labeling the data manually.

Another discussion point concerns our data. The image quality in terms of pixel size of our images is really high. Due to limited memory capacity and long runtimes of some of the tested networks, images needed to be down sampled. Additionally, images of different file types were used (e.g. png, jpg), which also includes reduction in disc space. We should further investigate to what extent images can be down sampled without losing critical information, in order to optimize the named difficulties.

Even though a variety three images of every asparagus spear are given, they are all taken from the same perspective – from above. In the ideal case, the asparagus spear rotates over the conveyor belt, such that each spear is depicted in the pictures from a different viewpoint. The better the asparagus rotates, the more reliable is a later judgement of the spear in terms of class labels or features. As the rotation often lacks, because the spear is too bent, an additional viewpoint could improve the rating. Concrete ideas how to improve the setup are given in the outlook.

As previously mentioned, our labels of asparagus features are partly achieved by computer-vision algorithms, partly based on human perception. As previously outlined, human performance is commonly acknowledged as the baseline performance in classification tasks. While the performance of our automatic feature-extraction for length and width is really high, we decided that for the features violet, rusty head, rusty body, bent, hollow and flower a human perception would be more accurate. Even though this is commonly used as the \enquote{gold standard}, it can of course also bring more variation, and maybe even inconsistency between raters, than an algorithm. 

As explained in the section ~\nameref{sec:Preprocessing}, during preprocessing for the labeling procedure, the three images of one asparagus spear are joined together and then labeled. Therefore labeling was faster, because three perspectives are labeled at once. However, it could also be tried to use the single perspectives and conclude the classes from a combination of the recognized features.

We kept the features binary, as this is easier to label, and easier to use for our supervised classification approaches. The down side of a binary label is, however, that a clear boundary is set, where in real life there is a smooth transition. Even for our supervising farmer, it is sometimes difficult to decide on a boundary. This is arguably due to the small differences between groups, and vague borders between positive and negative examples. While the binary representation makes certain analyses and classification much easier, it also brings restrictions.

Moreover, we observed difficulties concerning the labels in the communication between the group and the farmer. The communicated need is that the sorting algorithm works \enquote{better}. But what does that technically mean? And what is technically possible? For the farmer, the sorting would already be \enquote{better}, if the sorting mistakes would be more systematic. This would not necessarily mean that the overall accuracy of correctly sorted asparagus into one out of 13 class labels needs to improve, but that the overall impression of all spears sorted into one tray is more homogeneous. 


\subsection{Organization}
\label{sec:DiscussionOrganization}

This section summarizes and briefly discusses what each member has personally learned on an organizational level during the year.

The team did not only achieve new scientific skills and techniques of data acquisition, preparation, and analysis but also gained valuable new insights into the organization of a large project. It was learned how to structure the team more successfully and purposefully.

\bigskip
First and foremost, this needs excellent communication. Not everyone has to discuss or listen to each specific detail in every working area. Instead, communication should be balanced. Often, it suffices when all team members have a broad overview.

Secondly, it turns out to be helpful when one or two members exchange some task-related work in favor of more management-related work. Democratic decision making does not necessarily exclude the role of a team leader or of a manager who has an overview of the tasks or of a certain task area. The whole team agrees to structure the next project in the same way as done during the second term, including manager roles and a stricter working plan. By this, better team dynamics are gained and time management can be improved.

Further, the strengths of the single members have to be evaluated before the project starts so they can be used efficiently. Although, not everyone has to do the task he or she is best at. One should also have the opportunity to work on tasks that are new, challenging and interesting. It allows each member to broaden their skills and it avoids discouragement. 

Finally, the team agrees to have more focus on the overall goal than only think of what directly lies ahead. For this, concrete goals have to be formulated well. Milestones or intermediate goals should be defined and better checked. More time has to be taken into consideration when planning ahead as well as for including adjustments.

\bigskip
In conclusion, the experience of having two different working structures gave us the ability to compare and judge what is essential to successful teamwork. It also helped to understand how each member can contribute to the team regarding personal skills and interests, and what each member wants to improve for future teamwork.

As the main intention of the study project was to enhance our knowledge, we sought out a task that we were highly motivated to do. By that, we did not only practice theoretical knowledge but gained new experiences and sustainably improved our team skills for future work.