\section{Summary of classification results}

The current work was conducted to investigate the state of the art on asparagus classification and to improve the current sorting algorithm implemented at the XX machine at the Spargelhof Gut Holsterfeld. Data was collected, preprocessed and then analyzed with seven different approaches. Out of our XX (all images) images, (XX) were re-sorted in the machine and 13319 images manually labeled by us. Those labelled data was considered for the supervised approaches. The semi-supervised approach was additionally based on (XX) unlabeled images. The results illustrate that classifying asparagus is not a trivial problem. This is partly due to the small differences between groups, and vague borders within features. However, the results also show that it is possible to extract relevant features and to improve current sorting approaches. \\
\\
As supervised learning approaches, a MLP and a CNN are introduced for feature engineering, whereas the CNN only includes head related features. Following, single-label classification and multi-label classification are conducted. All these attempts aim to solve the same image classification problem, using supervised learning.
The MLP, as well as the CNN approach for head feature extraction were based on automated extracted labels, generated through computer based feature extraction, whereas all other approaches used the hand-labelled data. \\
\\
As the feature engineering MLP (mostly) and the single-label-classification CNN perform a binary classification (see 4.1.1, 4.1.3) and the CNN for head-related features as well as the multi-label approach perform a multi-label classification (chapter 4.1.2, 4.1.4), results are difficult to compare directly. With the random forest approach a third option, multiclass prediction is added. Multi-label classification is a more complex, holistic approach. Still, the results of the binary classification approaches yield a deeper insight on where difficulties lie and what features are more problematic than others.
The multiclass approach had an accuracy of 75\%. The accuracy for the CNN for head-related features was XX\%. Especially flower reached 55\% sensitivity, 95\% specificity while rusty head attained 19\% sensitivity and 98\% specificity. The accuracy of the Multi-label approach reached up to 87\%. For this model, accuracies werewhere not separated, to see accuracy feature wise. \\
\\
The accuracies for binary classification can be stated more specific: The feature engineering approach showed best results on curvature (82\% sensitivity, 67\% specificity) and worst results for rusty body (71\% sensitivity, 65\% specificity). In the single-label classification CNN, best results were achieved for the feature XX with a sensitivity of XX and a specificity of XX, while worst results were achieved for XX with a sensitivity of XX and a specificity of XX. Train accuracy did not notably exceed 50\%. The test accuracy usually increased up to XX - XX. \\
\\
The unsupervised learning approaches, one is referred to as PCA, the other as VAE, deal both with dimension reduction. Both were implemented, using the hand labelled data. Whereas the classification method of the PCA is based on binary feature prediction (absence or presence of a feature), the VAE does not predict labels. The accuracy of the PCA was promising for length and hollow (100\%) but extremely poor for bent (20\%). The accuracy of the VAE â€¦ \\
The last approach, a semi-supervised learning method was based on a partially labeled dataset. It performed multi-label classification. Unfortunately the predicted power was rather poor, best for curvature (18\% sensitivity, 96\% specificity) and worst for violet as it did not detect any violet pieces (0\% sensitivity). \\
\\
Evaluation 


